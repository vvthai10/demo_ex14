[core]
default-scheduler-host = localhost

[spark]
spark-submit:/opt/spark-3.5.3/bin/spark-submit
hadoop-conf-dir:/home/hdoop/hadoop-3.4.0/etc/hadoop
# yarn-conf-dir:$YARN_HOME
master:yarn
num-executors:2

# [hdfs]
# client = hadoopcli
# namenode = hdfs://localhost:9000
# hadoop_home = /home/hdoop/hadoop-3.4.0/
# hadoop_bin = /home/hdoop/hadoop-3.4.0/bin/hadoop
[hdfs]
client = hadoopcli
namenode_host = localhost
namenode_port = 9000

[hadoop]
command = /home/hdoop/hadoop-3.4.0/bin/hadoop
# [hadoop]
# home = /home/hdoop/hadoop-3.4.0
# bin = /home/hdoop/hadoop-3.4.0/bin

[worker]
no_install_shutdown_handler=True




